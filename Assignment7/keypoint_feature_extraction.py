"""
Keypoint ve Ã–zellik Ã‡Ä±karÄ±mÄ±
Assignment 7: SIFT, ORB, SURF, FAST gibi algoritmalar ile anlamlÄ± noktalarÄ±n tespiti

Bu dosya keypoint detection, feature extraction ve matching algoritmalarÄ±nÄ± Ã¶ÄŸretmek iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.
SIFT, ORB, SURF, FAST gibi popÃ¼ler algoritmalarÄ± kapsamlÄ± ÅŸekilde ele alÄ±r.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
from datetime import datetime

class KeypointFeatureExtraction:
    """
    Keypoint detection ve feature extraction algoritmalarÄ±nÄ± gÃ¶steren sÄ±nÄ±f
    """
    
    def __init__(self):
        """SÄ±nÄ±fÄ± baÅŸlatÄ±r ve gerekli klasÃ¶rleri oluÅŸturur"""
        self.create_directories()
        self.image_path1 = "images/image1.jpg"
        self.image_path2 = "images/image2.jpg"
        self.results_dir = "results"
        
    def create_directories(self):
        """Gerekli klasÃ¶rleri oluÅŸturur"""
        directories = [
            "images",
            "results",
            "results/keypoints", 
            "results/matching",
            "results/applications",
        ]
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
    
    def create_sample_images(self):
        """
        Demo iÃ§in Ã¶rnek gÃ¶rÃ¼ntÃ¼ler oluÅŸturur
        """
        # Ä°lk gÃ¶rÃ¼ntÃ¼ - karmaÅŸÄ±k desenler
        image1 = np.zeros((400, 400, 3), dtype=np.uint8)
        
        # FarklÄ± ÅŸekiller ve desenler
        cv2.rectangle(image1, (50, 50), (150, 150), (255, 0, 0), -1)
        cv2.circle(image1, (300, 100), 50, (0, 255, 0), -1)
        cv2.ellipse(image1, (200, 300), (60, 30), 45, 0, 360, (0, 0, 255), -1)
        
        # Ä°nce Ã§izgiler ve kÃ¶ÅŸeler
        for i in range(0, 400, 30):
            cv2.line(image1, (i, 0), (i+20, 50), (255, 255, 255), 2)
        
        # GÃ¼rÃ¼ltÃ¼ ekle
        noise = np.random.normal(0, 15, image1.shape).astype(np.uint8)
        image1 = cv2.add(image1, noise)
        
        # Metin ekle
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(image1, "Keypoint Detection", (20, 380), font, 0.6, (255, 255, 255), 2)
        
        # Ä°kinci gÃ¶rÃ¼ntÃ¼ - ilkinin dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ ve Ã¶lÃ§eklenmiÅŸ hali
        image2 = cv2.resize(image1, (300, 300))
        rows, cols = image2.shape[:2]
        M = cv2.getRotationMatrix2D((cols/2, rows/2), 30, 1)
        image2 = cv2.warpAffine(image2, M, (cols, rows))
        
        # GÃ¼rÃ¼ltÃ¼ ekle
        noise2 = np.random.normal(0, 20, image2.shape).astype(np.uint8)
        image2 = cv2.add(image2, noise2)
        
        # GÃ¶rÃ¼ntÃ¼leri kaydet
        cv2.imwrite(self.image_path1, image1)
        cv2.imwrite(self.image_path2, image2)
        print(f"âœ… Ã–rnek gÃ¶rÃ¼ntÃ¼ler oluÅŸturuldu: {self.image_path1}, {self.image_path2}")
    
    def demo_keypoint_detection(self):
        """
        FarklÄ± keypoint detection algoritmalarÄ±nÄ± gÃ¶sterir
        """
        print("\n" + "="*60)
        print("1. KEYPOINT DETECTION ALGORÄ°TMALARI")
        print("="*60)
        
        # GÃ¶rÃ¼ntÃ¼ yoksa oluÅŸtur
        if not os.path.exists(self.image_path1):
            self.create_sample_images()
        
        # GÃ¶rÃ¼ntÃ¼yÃ¼ oku
        image = cv2.imread(self.image_path1)
        if image is None:
            print("âŒ GÃ¶rÃ¼ntÃ¼ okunamadÄ±!")
            return None
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        print(f"\nğŸ“– Orijinal gÃ¶rÃ¼ntÃ¼ boyutu: {gray.shape}")
        
        # 1. Harris Corner Detection
        print(f"\nğŸ”§ 1. Harris Corner Detection:")
        harris = cv2.cornerHarris(gray, 2, 3, 0.04)
        harris = cv2.dilate(harris, None)
        
        # Keypoint'leri gÃ¶rselleÅŸtir
        harris_img = image.copy()
        harris_img[harris > 0.01 * harris.max()] = [0, 0, 255]
        
        cv2.imwrite(f"{self.results_dir}/keypoints/harris_corners.jpg", harris_img)
        print(f"   âœ… Harris Corners -> harris_corners.jpg")
        
        # 2. SIFT Keypoint Detection
        print(f"\nğŸ”§ 2. SIFT Keypoint Detection:")
        sift = cv2.SIFT_create()
        sift_keypoints, sift_descriptors = sift.detectAndCompute(gray, None)
        
        # Keypoint'leri gÃ¶rselleÅŸtir
        sift_img = cv2.drawKeypoints(image, sift_keypoints, None, 
                                    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
        cv2.imwrite(f"{self.results_dir}/keypoints/sift_keypoints.jpg", sift_img)
        print(f"   âœ… SIFT Keypoints ({len(sift_keypoints)}) -> sift_keypoints.jpg")
        
        # 3. ORB Keypoint Detection
        print(f"\nğŸ”§ 3. ORB Keypoint Detection:")
        orb = cv2.ORB_create(nfeatures=500)
        orb_keypoints, orb_descriptors = orb.detectAndCompute(gray, None)
        
        # Keypoint'leri gÃ¶rselleÅŸtir
        orb_img = cv2.drawKeypoints(image, orb_keypoints, None, 
                                   flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
        cv2.imwrite(f"{self.results_dir}/keypoints/orb_keypoints.jpg", orb_img)
        print(f"   âœ… ORB Keypoints ({len(orb_keypoints)}) -> orb_keypoints.jpg")
        
        # 4. FAST Keypoint Detection
        print(f"\nğŸ”§ 4. FAST Keypoint Detection:")
        fast = cv2.FastFeatureDetector_create(threshold=25)
        fast_keypoints = fast.detect(gray, None)
        
        # Keypoint'leri gÃ¶rselleÅŸtir
        fast_img = cv2.drawKeypoints(image, fast_keypoints, None, 
                                   flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
        cv2.imwrite(f"{self.results_dir}/keypoints/fast_keypoints.jpg", fast_img)
        print(f"   âœ… FAST Keypoints ({len(fast_keypoints)}) -> fast_keypoints.jpg")
        
        # 5. SURF Keypoint Detection (OpenCV 4.5.4+ gerekli)
        print(f"\nğŸ”§ 5. SURF Keypoint Detection:")
        try:
            surf = cv2.xfeatures2d.SURF_create(400)
            surf_keypoints, surf_descriptors = surf.detectAndCompute(gray, None)
            
            # Keypoint'leri gÃ¶rselleÅŸtir
            surf_img = cv2.drawKeypoints(image, surf_keypoints, None, 
                                       flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
            cv2.imwrite(f"{self.results_dir}/keypoints/surf_keypoints.jpg", surf_img)
            print(f"   âœ… SURF Keypoints ({len(surf_keypoints)}) -> surf_keypoints.jpg")
        except:
            print(f"   âš ï¸ SURF mevcut deÄŸil (OpenCV contrib gerekli)")
        
        # KarÅŸÄ±laÅŸtÄ±rma gÃ¶rÃ¼ntÃ¼sÃ¼
        comparison = np.hstack([image, harris_img, sift_img, orb_img, fast_img])
        cv2.imwrite(f"{self.results_dir}/keypoints/keypoint_comparison.jpg", comparison)
        print(f"   âœ… KarÅŸÄ±laÅŸtÄ±rma -> keypoint_comparison.jpg")
        
        return gray, sift_keypoints, sift_descriptors, orb_keypoints, orb_descriptors
    
    def demo_feature_matching(self, gray1, sift_kp1, sift_desc1, orb_kp1, orb_desc1):
        """
        Feature matching algoritmalarÄ±nÄ± gÃ¶sterir
        """
        print("\n" + "="*60)
        print("2. FEATURE MATCHING ALGORÄ°TMALARI")
        print("="*60)
        
        # Ä°kinci gÃ¶rÃ¼ntÃ¼yÃ¼ oku
        image2 = cv2.imread(self.image_path2)
        if image2 is None:
            print("âŒ Ä°kinci gÃ¶rÃ¼ntÃ¼ okunamadÄ±!")
            return None
        
        gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
        
        print(f"\nğŸ“– Ä°kinci gÃ¶rÃ¼ntÃ¼ boyutu: {gray2.shape}")
        
        # 1. SIFT Feature Matching
        print(f"\nğŸ”§ 1. SIFT Feature Matching:")
        sift = cv2.SIFT_create()
        sift_kp2, sift_desc2 = sift.detectAndCompute(gray2, None)
        
        # Brute Force Matcher
        bf = cv2.BFMatcher()
        sift_matches = bf.knnMatch(sift_desc1, sift_desc2, k=2)
        
        # Lowe's ratio test
        good_sift = []
        for match_pair in sift_matches:
            if len(match_pair) == 2:
                m, n = match_pair
                if m.distance < 0.75 * n.distance:
                    good_sift.append(m)
        
        # EÅŸleÅŸtirmeleri gÃ¶rselleÅŸtir
        image1 = cv2.imread(self.image_path1)
        sift_matching_img = cv2.drawMatches(image1, sift_kp1, image2, sift_kp2, 
                                           good_sift, None, 
                                           flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
        cv2.imwrite(f"{self.results_dir}/matching/sift_matching.jpg", sift_matching_img)
        print(f"   âœ… SIFT Matching ({len(good_sift)} matches) -> sift_matching.jpg")
        
        # 2. ORB Feature Matching
        print(f"\nğŸ”§ 2. ORB Feature Matching:")
        orb = cv2.ORB_create(nfeatures=500)
        orb_kp2, orb_desc2 = orb.detectAndCompute(gray2, None)
        
        # Hamming distance iÃ§in BF Matcher
        bf_orb = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        orb_matches = bf_orb.match(orb_desc1, orb_desc2)
        
        # En iyi eÅŸleÅŸtirmeleri seÃ§
        orb_matches = sorted(orb_matches, key=lambda x: x.distance)
        good_orb = orb_matches[:int(len(orb_matches) * 0.75)]
        
        # EÅŸleÅŸtirmeleri gÃ¶rselleÅŸtir
        orb_matching_img = cv2.drawMatches(image1, orb_kp1, image2, orb_kp2, 
                                          good_orb, None, 
                                          flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
        cv2.imwrite(f"{self.results_dir}/matching/orb_matching.jpg", orb_matching_img)
        print(f"   âœ… ORB Matching ({len(good_orb)} matches) -> orb_matching.jpg")
        
        # 3. FLANN Matching (SIFT iÃ§in)
        print(f"\nğŸ”§ 3. FLANN Matching:")
        FLANN_INDEX_KDTREE = 1
        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
        search_params = dict(checks=50)
        
        flann = cv2.FlannBasedMatcher(index_params, search_params)
        flann_matches = flann.knnMatch(sift_desc1, sift_desc2, k=2)
        
        # Lowe's ratio test
        good_flann = []
        for match_pair in flann_matches:
            if len(match_pair) == 2:
                m, n = match_pair
                if m.distance < 0.7 * n.distance:
                    good_flann.append(m)
        
        # EÅŸleÅŸtirmeleri gÃ¶rselleÅŸtir
        flann_matching_img = cv2.drawMatches(image1, sift_kp1, image2, sift_kp2, 
                                            good_flann, None, 
                                            flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
        cv2.imwrite(f"{self.results_dir}/matching/flann_matching.jpg", flann_matching_img)
        print(f"   âœ… FLANN Matching ({len(good_flann)} matches) -> flann_matching.jpg")
        
        return gray2, sift_kp2, orb_kp2, good_sift, good_orb, good_flann
    
    def demo_homography_and_applications(self, gray1, gray2, sift_kp1, sift_kp2, 
                                       orb_kp1, orb_kp2, good_sift, good_orb):
        """
        Homography hesaplama ve gerÃ§ek dÃ¼nya uygulamalarÄ±nÄ± gÃ¶sterir
        """
        print("\n" + "="*60)
        print("3. HOMOGRAPHY VE UYGULAMALAR")
        print("="*60)
        
        # 1. Homography Estimation (SIFT ile)
        print(f"\nğŸ”§ 1. Homography Estimation:")
        if len(good_sift) >= 4:
            # Keypoint'lerin koordinatlarÄ±nÄ± al
            src_pts = np.float32([sift_kp1[m.queryIdx].pt for m in good_sift]).reshape(-1, 1, 2)
            dst_pts = np.float32([sift_kp2[m.trainIdx].pt for m in good_sift]).reshape(-1, 1, 2)
            
            # Homography hesapla
            H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
            
            if H is not None:
                # Perspektif dÃ¶nÃ¼ÅŸÃ¼m uygula
                h, w = gray1.shape
                pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)
                dst = cv2.perspectiveTransform(pts, H)
                
                # DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ gÃ¶rÃ¼ntÃ¼yÃ¼ Ã§iz
                image1 = cv2.imread(self.image_path1)
                image2 = cv2.imread(self.image_path2)
                transformed_img = cv2.polylines(image2.copy(), [np.int32(dst)], True, (0, 255, 0), 3)
                
                cv2.imwrite(f"{self.results_dir}/applications/homography_result.jpg", transformed_img)
                print(f"   âœ… Homography Result -> homography_result.jpg")
        
        # 2. Image Stitching (Basit panorama)
        #print(f"\nğŸ”§ 2. Image Stitching:")
        #if len(good_sift) >= 10:
            # Warp perspektif
            #h1, w1 = gray1.shape
            #h2, w2 = gray2.shape
            
            # Ä°kinci gÃ¶rÃ¼ntÃ¼yÃ¼ birinci gÃ¶rÃ¼ntÃ¼nÃ¼n koordinat sistemine dÃ¶nÃ¼ÅŸtÃ¼r
            #warped_img = cv2.warpPerspective(image2, H, (w1 + w2, h1))
            
            # GÃ¶rÃ¼ntÃ¼leri birleÅŸtir
            #warped_img[0:h1, 0:w1] = image1
            
            #cv2.imwrite(f"{self.results_dir}/applications/image_stitching.jpg", warped_img)
            #print(f"   âœ… Image Stitching -> image_stitching.jpg")
        
        # 3. Object Detection (Template matching ile)
        print(f"\nğŸ”§ 3. Object Detection:")
        # Ä°lk gÃ¶rÃ¼ntÃ¼den bir bÃ¶lgeyi template olarak al
        template = gray1[100:200, 100:200]
        
        # Template matching
        result = cv2.matchTemplate(gray2, template, cv2.TM_CCOEFF_NORMED)
        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
        
        # EÅŸleÅŸen bÃ¶lgeyi iÅŸaretle
        h, w = template.shape
        image2_with_detection = cv2.imread(self.image_path2)
        cv2.rectangle(image2_with_detection, max_loc, (max_loc[0] + w, max_loc[1] + h), (0, 255, 0), 2)
        
        cv2.imwrite(f"{self.results_dir}/applications/object_detection.jpg", image2_with_detection)
        print(f"   âœ… Object Detection -> object_detection.jpg")
        
        # 4. Feature Density Analysis
        print(f"\nğŸ”§ 4. Feature Density Analysis:")
        # Keypoint yoÄŸunluÄŸunu analiz et
        sift_density = len(sift_kp1) / (gray1.shape[0] * gray1.shape[1])
        orb_density = len(orb_kp1) / (gray1.shape[0] * gray1.shape[1])
        
        # YoÄŸunluk haritasÄ± oluÅŸtur
        density_map = np.zeros_like(gray1)
        for kp in sift_kp1:
            x, y = int(kp.pt[0]), int(kp.pt[1])
            cv2.circle(density_map, (x, y), 5, 255, -1)
        
        # Gaussian blur ile yumuÅŸat
        density_map = cv2.GaussianBlur(density_map, (15, 15), 0)
        
        # Heatmap olarak kaydet
        plt.figure(figsize=(8, 6))
        plt.imshow(density_map, cmap='hot')
        plt.colorbar()
        plt.title('Feature Density Map')
        plt.savefig(f"{self.results_dir}/applications/feature_density_map.jpg")
        plt.close()
        
        print(f"   âœ… Feature Density Map -> feature_density_map.jpg")
        print(f"   ğŸ“Š SIFT Density: {sift_density:.6f}, ORB Density: {orb_density:.6f}")
    
    def demo_performance_comparison(self, gray1, gray2):
        """
        FarklÄ± algoritmalarÄ±n performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±r
        """
        print("\n" + "="*60)
        print("4. PERFORMANS KARÅILAÅTIRMASI")
        print("="*60)
        
        algorithms = {
            'SIFT': cv2.SIFT_create(),
            'ORB': cv2.ORB_create(nfeatures=500),
            'FAST': cv2.FastFeatureDetector_create(threshold=25)
        }
        
        results = {}
        
        for name, detector in algorithms.items():
            print(f"\nğŸ”§ {name} Performance:")
            
            # Keypoint detection sÃ¼resi
            start_time = cv2.getTickCount()
            if name == 'FAST':
                keypoints = detector.detect(gray1, None)
                descriptors = None
            else:
                keypoints, descriptors = detector.detectAndCompute(gray1, None)
            end_time = cv2.getTickCount()
            
            detection_time = (end_time - start_time) / cv2.getTickFrequency()
            
            # Matching sÃ¼resi (descriptor varsa)
            matching_time = 0
            match_count = 0
            if descriptors is not None:
                # Ä°kinci gÃ¶rÃ¼ntÃ¼den de Ã¶zellikler Ã§Ä±kar
                kp2, desc2 = detector.detectAndCompute(gray2, None)
                
                if desc2 is not None and len(desc2) > 0:
                    # Matching
                    if name == 'ORB':
                        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
                    else:
                        matcher = cv2.BFMatcher()
                    
                    start_time = cv2.getTickCount()
                    matches = matcher.match(descriptors, desc2)
                    end_time = cv2.getTickCount()
                    
                    matching_time = (end_time - start_time) / cv2.getTickFrequency()
                    match_count = len(matches)
            
            results[name] = {
                'keypoints': len(keypoints),
                'detection_time': detection_time,
                'matching_time': matching_time,
                'matches': match_count
            }
            
            print(f"   ğŸ“Š Keypoints: {len(keypoints)}")
            print(f"   â±ï¸ Detection Time: {detection_time:.4f}s")
            print(f"   â±ï¸ Matching Time: {matching_time:.4f}s")
            print(f"   ğŸ”— Matches: {match_count}")
        
        # SonuÃ§larÄ± gÃ¶rselleÅŸtir
        self.plot_performance_results(results)
        
        return results
    
    def plot_performance_results(self, results):
        """
        Performans sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirir
        """
        names = list(results.keys())
        keypoint_counts = [results[name]['keypoints'] for name in names]
        detection_times = [results[name]['detection_time'] for name in names]
        matching_times = [results[name]['matching_time'] for name in names]
        match_counts = [results[name]['matches'] for name in names]
        
        # Ã‡oklu grafik oluÅŸtur
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))
        
        # Keypoint sayÄ±sÄ±
        ax1.bar(names, keypoint_counts, color=['red', 'blue', 'green'])
        ax1.set_title('Keypoint Count')
        ax1.set_ylabel('Number of Keypoints')
        
        # Detection sÃ¼resi
        ax2.bar(names, detection_times, color=['red', 'blue', 'green'])
        ax2.set_title('Detection Time')
        ax2.set_ylabel('Time (seconds)')
        
        # Matching sÃ¼resi
        ax3.bar(names, matching_times, color=['red', 'blue', 'green'])
        ax3.set_title('Matching Time')
        ax3.set_ylabel('Time (seconds)')
        
        # Match sayÄ±sÄ±
        ax4.bar(names, match_counts, color=['red', 'blue', 'green'])
        ax4.set_title('Match Count')
        ax4.set_ylabel('Number of Matches')
        
        plt.tight_layout()
        plt.savefig(f"{self.results_dir}/applications/performance_comparison.jpg")
        plt.close()
        
        print(f"   âœ… Performance Comparison -> performance_comparison.jpg")
    
    def run_demo(self):
        """
        TÃ¼m demo'larÄ± Ã§alÄ±ÅŸtÄ±rÄ±r
        """
        print("ğŸš€ Keypoint ve Ã–zellik Ã‡Ä±karÄ±mÄ± Demo BaÅŸlÄ±yor...")
        print("="*60)
        
        try:
            # 1. Keypoint detection
            result = self.demo_keypoint_detection()
            if result is None:
                print("âŒ Demo baÅŸlatÄ±lamadÄ±!")
                return
            
            gray1, sift_kp1, sift_desc1, orb_kp1, orb_desc1 = result
            
            # 2. Feature matching
            result2 = self.demo_feature_matching(gray1, sift_kp1, sift_desc1, orb_kp1, orb_desc1)
            if result2 is None:
                print("âŒ Feature matching baÅŸlatÄ±lamadÄ±!")
                return
            
            gray2, sift_kp2, orb_kp2, good_sift, good_orb, good_flann = result2
            
            # 3. Homography ve uygulamalar
            self.demo_homography_and_applications(gray1, gray2, sift_kp1, sift_kp2, 
                                                orb_kp1, orb_kp2, good_sift, good_orb)
            
            # 4. Performans karÅŸÄ±laÅŸtÄ±rmasÄ±
            self.demo_performance_comparison(gray1, gray2)
            
            print("\n" + "="*60)
            print("ğŸ‰ Keypoint ve Ã–zellik Ã‡Ä±karÄ±mÄ± Demo tamamlandÄ±!")
            print("ğŸ“ SonuÃ§lar 'results' klasÃ¶rÃ¼nde bulunabilir")
            print("ğŸ“š README.md dosyasÄ±nÄ± inceleyerek Ã¶ÄŸrenilenleri gÃ¶zden geÃ§irin")
            print("="*60)
            
        except Exception as e:
            print(f"âŒ Hata oluÅŸtu: {e}")

if __name__ == "__main__":
    # Demo'yu baÅŸlat
    demo = KeypointFeatureExtraction()
    demo.run_demo() 